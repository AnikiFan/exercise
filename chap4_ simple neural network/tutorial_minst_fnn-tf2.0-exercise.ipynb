{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        ####################\n",
    "        '''声明模型对应的参数'''\n",
    "        ####################\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "        \n",
    "model = myModel()\n",
    "model.train()\n",
    "optimizer = Adam(model.parameters(),lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    return CrossEntropyLoss()(logits,labels)\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    return (predictions == labels).to(float).mean()\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    # loss and accuracy is scalar tensor\n",
    "    return loss, accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, x, y):\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(train_ratio=0.8):\n",
    "    mnist = MNIST(root=\".\",download=True)\n",
    "    data,targets = mnist.data/255,mnist.targets\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data = (data-data.mean(axis=1,keepdims=True))/data.std(axis=1,keepdims=True)\n",
    "    idx = np.arange(data.shape[0])\n",
    "    train_idx = np.zeros_like(idx)\n",
    "    train_idx[np.random.choice(idx,int(train_ratio*data.shape[0]),replace=False)] = 1\n",
    "    train_x,train_y = data[train_idx.astype(bool)],targets[train_idx.astype(bool)]\n",
    "    test_x,test_y = data[train_idx.astype(bool)],targets[train_idx.astype(bool)]\n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 2.3192737102508545 ; accuracy 0.10285416666666666\n",
      "epoch 1 : loss 2.306709051132202 ; accuracy 0.1091875\n",
      "epoch 2 : loss 2.2947072982788086 ; accuracy 0.11625\n",
      "epoch 3 : loss 2.2829203605651855 ; accuracy 0.12464583333333333\n",
      "epoch 4 : loss 2.271228313446045 ; accuracy 0.13447916666666668\n",
      "epoch 5 : loss 2.2595834732055664 ; accuracy 0.14595833333333333\n",
      "epoch 6 : loss 2.247954845428467 ; accuracy 0.15985416666666666\n",
      "epoch 7 : loss 2.2363288402557373 ; accuracy 0.17522916666666666\n",
      "epoch 8 : loss 2.224700927734375 ; accuracy 0.19083333333333333\n",
      "epoch 9 : loss 2.213066816329956 ; accuracy 0.2075\n",
      "epoch 10 : loss 2.2014267444610596 ; accuracy 0.22489583333333332\n",
      "epoch 11 : loss 2.1897835731506348 ; accuracy 0.24116666666666667\n",
      "epoch 12 : loss 2.1781351566314697 ; accuracy 0.25854166666666667\n",
      "epoch 13 : loss 2.1664791107177734 ; accuracy 0.27589583333333334\n",
      "epoch 14 : loss 2.154816150665283 ; accuracy 0.2921875\n",
      "epoch 15 : loss 2.1431570053100586 ; accuracy 0.30954166666666666\n",
      "epoch 16 : loss 2.13149356842041 ; accuracy 0.327625\n",
      "epoch 17 : loss 2.119826316833496 ; accuracy 0.3460625\n",
      "epoch 18 : loss 2.108156204223633 ; accuracy 0.3637708333333333\n",
      "epoch 19 : loss 2.0964739322662354 ; accuracy 0.38145833333333334\n",
      "epoch 20 : loss 2.0847837924957275 ; accuracy 0.3980208333333333\n",
      "epoch 21 : loss 2.073082447052002 ; accuracy 0.4155625\n",
      "epoch 22 : loss 2.0613701343536377 ; accuracy 0.43216666666666664\n",
      "epoch 23 : loss 2.0496439933776855 ; accuracy 0.4482291666666667\n",
      "epoch 24 : loss 2.0379061698913574 ; accuracy 0.4642291666666667\n",
      "epoch 25 : loss 2.026150941848755 ; accuracy 0.4771458333333333\n",
      "epoch 26 : loss 2.0143747329711914 ; accuracy 0.49135416666666665\n",
      "epoch 27 : loss 2.002580165863037 ; accuracy 0.5043541666666667\n",
      "epoch 28 : loss 1.9907602071762085 ; accuracy 0.518\n",
      "epoch 29 : loss 1.9789106845855713 ; accuracy 0.5311458333333333\n",
      "epoch 30 : loss 1.9670288562774658 ; accuracy 0.5430833333333334\n",
      "epoch 31 : loss 1.9551225900650024 ; accuracy 0.5545625\n",
      "epoch 32 : loss 1.9431908130645752 ; accuracy 0.5658333333333333\n",
      "epoch 33 : loss 1.9312303066253662 ; accuracy 0.5764375\n",
      "epoch 34 : loss 1.9192426204681396 ; accuracy 0.5863958333333333\n",
      "epoch 35 : loss 1.9072318077087402 ; accuracy 0.5953541666666666\n",
      "epoch 36 : loss 1.8951915502548218 ; accuracy 0.6033333333333334\n",
      "epoch 37 : loss 1.8831230401992798 ; accuracy 0.6110625\n",
      "epoch 38 : loss 1.8710291385650635 ; accuracy 0.6187916666666666\n",
      "epoch 39 : loss 1.8588982820510864 ; accuracy 0.6258541666666667\n",
      "epoch 40 : loss 1.8467304706573486 ; accuracy 0.6321875\n",
      "epoch 41 : loss 1.8345253467559814 ; accuracy 0.6374583333333333\n",
      "epoch 42 : loss 1.822279930114746 ; accuracy 0.6426458333333334\n",
      "epoch 43 : loss 1.8099948167800903 ; accuracy 0.6465833333333333\n",
      "epoch 44 : loss 1.7976672649383545 ; accuracy 0.6507708333333333\n",
      "epoch 45 : loss 1.785302758216858 ; accuracy 0.6555416666666667\n",
      "epoch 46 : loss 1.7728979587554932 ; accuracy 0.6587291666666667\n",
      "epoch 47 : loss 1.760452151298523 ; accuracy 0.6613125\n",
      "epoch 48 : loss 1.7479698657989502 ; accuracy 0.665125\n",
      "epoch 49 : loss 1.735451340675354 ; accuracy 0.6681041666666667\n",
      "test loss 1.7228955030441284 ; accuracy 0.6709583333333333\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y,test_x,test_y= mnist_dataset()\n",
    "for epoch in range(50):\n",
    "    loss, accuracy = train_one_step(model, optimizer,train_x,train_y)\n",
    "    print('epoch', epoch, ': loss', loss.item(), '; accuracy', accuracy.item())\n",
    "loss, accuracy = test(model, \n",
    "                      test_x, \n",
    "                      test_y)\n",
    "\n",
    "print('test loss', loss.item(), '; accuracy', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
